{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b07b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0f03a",
   "metadata": {},
   "source": [
    "## Pivot subway data from long to wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "40e3eaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#access subway data\n",
    "#number of days in month * 143 unique stations = one month of entries\n",
    "url_sc = 'https://data.cityofchicago.org/resource/5neh-572f.json?$where=date%20%3E%272021-05-15%27&$limit=4433'\n",
    "subway_df_closed = pd.read_json(url_sc)\n",
    "\n",
    "url_so = 'https://data.cityofchicago.org/resource/5neh-572f.json?$where=date%20%3E%272021-04-15%27&$limit=4290'\n",
    "subway_df_open = pd.read_json(url_so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5f58e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df_closed\n",
    "\n",
    "# reshape from long to wide in pandas python\n",
    "\n",
    "subway_df_closed_wide = subway_df_closed.pivot(index = 'date', columns='stationname', values='rides').reset_index()\n",
    "subway_df_open_wide = subway_df_open.pivot(index = 'date', columns='stationname', values='rides').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2f5ef",
   "metadata": {},
   "source": [
    "## Iteratively add SRI segements to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6cda774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "def dates(startyear, startmon, startday, endyear, endmon, endday): #in (year, month, day) format\n",
    "    start_date = date(startyear, startmon, startday) \n",
    "    end_date = date(endyear, endmon, endday)    # perhaps date.now()\n",
    "\n",
    "    delta = end_date - start_date   # returns timedelta\n",
    "    days = []\n",
    "    for i in range(delta.days + 1):\n",
    "        day = start_date + timedelta(days=i)\n",
    "        days.append(str(day))\n",
    "    return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40dc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = dates(2018,3,5,2021,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42054ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SRI_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-05</td>\n",
       "      <td>4.061097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>3.000957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-07</td>\n",
       "      <td>3.352608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-08</td>\n",
       "      <td>3.802497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>7.419558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>2.815171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>3.568193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>2.350644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>4.618797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>2.959930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   SRI_max\n",
       "0     2018-03-05  4.061097\n",
       "1     2018-03-06  3.000957\n",
       "2     2018-03-07  3.352608\n",
       "3     2018-03-08  3.802497\n",
       "4     2018-03-09  7.419558\n",
       "...          ...       ...\n",
       "1091  2021-02-28  2.815171\n",
       "1092  2021-03-01  3.568193\n",
       "1093  2021-03-02  2.350644\n",
       "1094  2021-03-03  4.618797\n",
       "1095  2021-03-04  2.959930\n",
       "\n",
       "[1096 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test behavior with one sample csv\n",
    "df = pd.read_csv('/Users/amandakhoo/code/data4all-team6/data/SRI/1_SRI.csv')\n",
    "maxtest = []\n",
    "for day in days:\n",
    "    maxtest.append(df.loc[df['time'].str.contains(day), 'SRI'].max())\n",
    "    \n",
    "testdf = pd.DataFrame()\n",
    "testdf['date'] = days\n",
    "testdf['SRI_max'] = maxtest\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c47d52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amandakhoo/code/data4all-team6/data/SRI/\n",
      "/Users/amandakhoo/code/data4all-team6/data/SRI/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5c/_dfm1tzd7xv8v4dgb843ng300000gn/T/ipykernel_31373/3126015583.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRI[column_name] = daily_max_SRI\n",
      "/var/folders/5c/_dfm1tzd7xv8v4dgb843ng300000gn/T/ipykernel_31373/3126015583.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRI[column_name] = daily_max_SRI\n",
      "/var/folders/5c/_dfm1tzd7xv8v4dgb843ng300000gn/T/ipykernel_31373/3126015583.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRI[column_name] = daily_max_SRI\n",
      "/var/folders/5c/_dfm1tzd7xv8v4dgb843ng300000gn/T/ipykernel_31373/3126015583.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRI[column_name] = daily_max_SRI\n",
      "/var/folders/5c/_dfm1tzd7xv8v4dgb843ng300000gn/T/ipykernel_31373/3126015583.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRI[column_name] = daily_max_SRI\n",
      "/var/folders/5c/_dfm1tzd7xv8v4dgb843ng300000gn/T/ipykernel_31373/3126015583.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRI[column_name] = daily_max_SRI\n",
      "/var/folders/5c/_dfm1tzd7xv8v4dgb843ng300000gn/T/ipykernel_31373/3126015583.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRI[column_name] = daily_max_SRI\n",
      "/var/folders/5c/_dfm1tzd7xv8v4dgb843ng300000gn/T/ipykernel_31373/3126015583.py:38: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  SRI[column_name] = daily_max_SRI\n"
     ]
    }
   ],
   "source": [
    "#run for all csvs in SRI folder (~over 1000 segments)\n",
    "import os\n",
    "import glob\n",
    "  \n",
    "# use glob to get all the csv files \n",
    "# in the folder\n",
    "path = os.getcwd() + '/data/SRI/'\n",
    "print(path) #this should be the same as the path to where the csvs are\n",
    "print('/Users/amandakhoo/code/data4all-team6/data/SRI/')\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "  \n",
    "days = dates(2018,3,5,2021,3,4)\n",
    "SRI = pd.DataFrame()\n",
    "SRI['date'] = days\n",
    "daily_max_SRIs = []\n",
    "    \n",
    "# loop over the list of csv files\n",
    "for f in csv_files:\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    #iterate over the days of interest\n",
    "    for day in days:\n",
    "        daily_max_SRI = df.loc[df['time'].str.contains(day), 'SRI'].max()\n",
    "        daily_max_SRIs.append(daily_max_SRI)\n",
    "    \n",
    "    #add date column to the SRI df\n",
    "    \n",
    "    # print the location and filename\n",
    "    #print('Location:', f)\n",
    "    #print('File Name:', f.split(\"\\\\\")[-1])\n",
    "    \n",
    "    #add new columns by segment ID with max SRI per day\n",
    "    file_name = f.split(\"\\\\\")[-1]\n",
    "    segment = file_name.split('/')[-1].split('.')[0].split('_')[0] #get the segement number from the filename\n",
    "    column_name = 'segment_' + segment + '_max_SRI'\n",
    "    \n",
    "    SRI[column_name] = daily_max_SRI\n",
    "    \n",
    "    \n",
    "#pd.concat([SRI, df['SRI']], axis = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710a89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRI.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f67de7",
   "metadata": {},
   "source": [
    "## Combine SRI and Subway data\n",
    "where the dates match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d921dd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.cityofchicago.org/resource/5neh-572f.json?$where=date%20%3E%272018-04-08%27&$limit=4433'\n",
    "subway_df = pd.read_json(url)\n",
    "subway_df_wide = subway_df.pivot(index = 'date', columns='stationname', values='rides').reset_index()\n",
    "\n",
    "#change all date types to object\n",
    "subway_df_wide['date'] = subway_df_wide['date'].dt.date.astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2b22839b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-04-09', '2018-04-10', '2018-04-11', '2018-04-12',\n",
       "       '2018-04-13', '2018-04-14', '2018-04-15', '2018-04-16',\n",
       "       '2018-04-17', '2018-04-18', '2018-04-19', '2018-04-20',\n",
       "       '2018-04-21', '2018-04-22', '2018-04-23', '2018-04-24',\n",
       "       '2018-04-25', '2018-04-26', '2018-04-27', '2018-04-28',\n",
       "       '2018-04-29', '2018-04-30', '2018-05-01', '2018-05-02',\n",
       "       '2018-05-03', '2018-05-04', '2018-05-05', '2018-05-06',\n",
       "       '2018-05-07', '2018-05-08', '2018-05-09'], dtype=object)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = subway_df_wide['date'].values\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e1edd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRI_subway_subset = SRI[SRI['date'].isin(dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "03b79b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date               object\n",
      "segment_37_SRI    float64\n",
      "segment_27_SRI    float64\n",
      "segment_55_SRI    float64\n",
      "segment_45_SRI    float64\n",
      "                   ...   \n",
      "segment_14_SRI    float64\n",
      "segment_22_SRI    float64\n",
      "segment_32_SRI    float64\n",
      "segment_40_SRI    float64\n",
      "segment_50_SRI    float64\n",
      "Length: 91, dtype: object\n",
      "stationname\n",
      "date                    object\n",
      "18th                   float64\n",
      "35-Bronzeville-IIT     float64\n",
      "35th/Archer            float64\n",
      "43rd                   float64\n",
      "                        ...   \n",
      "Western-Cermak         float64\n",
      "Western-Forest Park    float64\n",
      "Western-Orange         float64\n",
      "Western/Milwaukee      float64\n",
      "Wilson                 float64\n",
      "Length: 145, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(SRI_subway_subset.dtypes)\n",
    "print(subway_df_wide.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "72d64f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge\n",
    "merged_subway_SRI_df = SRI_subway_subset.merge(subway_df_wide, on = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ecc97b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_subway_SRI_df.to_csv('data/SAMPLE_subway_SRI_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b5835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
